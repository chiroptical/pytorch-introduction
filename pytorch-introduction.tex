%\PassOptionsToPackae{gray}{xcolor}
\documentclass[hyperref={pdfpagelabels=false},12pt]{beamer}
\setbeamertemplate{frametitle}[default][center]
\mode<presentation>
{
 \usetheme{Warsaw}      % or try Darmstadt, Madrid, Warsaw, ...
 \usecolortheme{default} % or try albatross, beaver, crane, ...
 \usefonttheme{default}  % or try serif, structurebold, ...
 \setbeamertemplate{footline}[frame number]
 \setbeamertemplate{caption}[numbered]
}

\usepackage[utf8]{inputenc}
\usepackage{helvet}
\usepackage{minted}
%\usepackage{bm}
%\usepackage{mathtools}
%\usepackage{listings}
%\usepackage{gensymb}
%\usepackage{array}
%\usepackage{times}
%\usepackage{xcolor}
%\usepackage{default}
%\usepackage{hyperref}
%\usepackage{booktabs}

% Great Commands
\newcommand{\ig}[2]{\includegraphics[width=#1\linewidth]{#2}}
\newcommand{\mybutton}[2]{\hyperlink{#1}{\beamerbutton{{#2}}}}
\newcommand{\myvbutton}[2]{\vfill\hyperlink{#1}{\beamerbutton{{#2}}}}
\newcommand{\code}[2]{\mintinline{#1}{#2}}
\newcommand{\python}[1]{\code{python}{#1}}
\newcommand{\bash}[1]{\code{bash}{#1}}
\newcommand{\unnamedUrl}[1]{\href{#1}{\color{blue}{#1}}}
\newcommand{\namedUrl}[2]{\href{#1}{\color{blue}{#2}}}
\newcommand{\pygment}[3]{\inputminted[bgcolor=lightgray,linenos,fontsize=#1]{#2}{#3}}
\newcommand{\pygmentLines}[5]{\inputminted[bgcolor=lightgray,linenos,fontsize=#1,firstline=#2,lastline=#3,autogobble]{#4}{#5}}

% Color Scheme
\definecolor{pittblue}{RGB}{28,41,87}
\definecolor{pittgold}{RGB}{205,184,125}
\setbeamercolor{structure}{fg=pittgold}
\setbeamercolor{button}{bg=pittblue}

\title[PyTorch]{{Introduction to PyTorch}}
\author[PyTorch]{{Barry Moore II}}
\institute[CRC]{Center for Research Computing \\ University of Pittsburgh}
\date{}

\beamertemplatenavigationsymbolsempty

\begin{document}

\begin{frame}{Getting the Slides}
  \begin{itemize}
    \item Download slides from
      \namedUrl{https://github.com/chiroptical/pytorch-introduction/releases/latest/download/pytorch-introduction.pdf}{https://tinyurl.com/introtorch}
    \item In Chrome or Firefox (Safari and Explorer won't work),
    \begin{itemize}
      \item navigate to \unnamedUrl{https://hub.crc.pitt.edu}
      \item authenticate with Pitt Passport
      \item when you see ``Server Options'',
        click big orange ``Start'' button (leave drop-down as ``Host Process'')
      \item Wait patiently for the application to load, go to next slide
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Getting the Notebooks}
  \begin{itemize}
    \item Page should look like,
  \end{itemize}
  \centering {
    \ig{0.75}{figures/lab.png}
  }
  \begin{itemize}
    \item Click the button pointed to by the arrow
    \item In the new window, type the following and hit return
  \end{itemize}
  \pygment{\scriptsize}{bash}{code/git-clone}
\end{frame}

\begin{frame}[plain]
\titlepage
\end{frame}

\begin{frame}{Notes...}
  \begin{itemize}
    \item Interrupt me at any time if something is unclear
    \item I am learning how to teach this
    \item Comments here \unnamedUrl{https://forms.gle/EzNzAxFkLBXgohCL6}, e.g.
    \begin{itemize}
      \item Slide 10, I found the exercise confusing because \dots
      \item Slide 13, line 9 could use more explanation
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Outline}
  \begin{itemize}
    \item Neurons and automatic differentiation
    \item A basic model from scratch
    \item PyTorch datasets and dataloaders
    \item A basic dense neural net
    \item Convolutional neural nets and transfer learning
  \end{itemize}
\end{frame}

\begin{frame}{Neuron}
  \centering
  \ig{0.75}{figures/neuron.png}
  \begin{itemize}
      \item $f$ is a function which takes $x$ and $y$ as input and produces $z$
      \item The \dots represents connections to other neurons
      \item This network of neurons forms a directed acyclic graph
  \end{itemize}
\end{frame}

\begin{frame}{Exercise}
  \centering
  \ig{0.75}{figures/neuron.png}
  \begin{enumerate}
    \item How would we represent $f$ in Python?
  \end{enumerate}
\end{frame}

\begin{frame}{Automatic differentiation: how?}
  \centering
  \ig{0.5}{figures/autograd.png}
  \begin{itemize}
      \item Top. Forward pass
      \item Bottom. Backward pass
      \item Using chain rule,
        \begin{align*}
          \frac{\partial L}{\partial x} &= \frac{\partial L}{\partial z} \cdot
                    \frac{\partial z}{\partial x}
        \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}{Directed acyclic graph: exercise}
  \begin{itemize}
      \item Given:
        \begin{align*}
          f(x) &= x * w = \hat{y} \\
          L(\hat{y}, y) &= \frac{1}{2}(\hat{y} - y)^2 = o
        \end{align*}
      \item $x$ is some input
      \item $w$ is a linear weight
      \item $\hat{y}$ is a prediction
      \item $L$ is the mean squared error loss function
      \item $o$ is the output of the loss function
      \item Try writing out the directed acyclic graph
  \end{itemize}
\end{frame}

\begin{frame}{Why use machine learning?}
  \begin{itemize}
    \item Given:
      \begin{align*}
        f(x) &= x * w = \hat{y} \\
        L(\hat{y}, y) &= \frac{1}{2}(\hat{y} - y)^2 = o
      \end{align*}
    \item Automatically determine $w$ by minimizing $L$ for a specific set of
      inputs $x$ with labels $y$ using gradient descent
  \end{itemize}
\end{frame}

\begin{frame}{What is gradient descent?}
  \vspace*{-0.5cm}
  \centering
  \ig{0.4}{figures/gradient-descent.png}
  \begin{itemize}
    \item Reality: $n$-dimensional parameter space
    \item Magnitude of arrow represents learning rate
    \item Lowest point is a local minima
    \item Thought experiment: what would happen if the learning rate was large?
      small?
  \end{itemize}
\end{frame}

\begin{frame}{PyTorch by example: inputs}
  \centering
  \pygment{\scriptsize}{python}{code/basic-training.0.py}
  \vspace{-0.75cm}
  \begin{columns}
    \column{0.5\textwidth}
      \vspace{-2cm}
      \begin{align*}
        f(x) &= x * w = \hat{y} \\
        L(\hat{y}, y) &= \frac{1}{2}(\hat{y} - y)^2 = o
      \end{align*}
    \column{0.5\textwidth}
      \ig{1.0}{figures/2x.png}
  \end{columns}
\end{frame}

\begin{frame}{PyTorch by example: forward and loss}
  \pygment{\scriptsize}{python}{code/basic-training.1.py}
  \begin{align*}
    f(x) &= x * w = \hat{y} \\
    L(\hat{y}, y) &= \frac{1}{2}(\hat{y} - y)^2 = o
  \end{align*}
\end{frame}

\begin{frame}{PyTorch by example: training}
  \pygment{\scriptsize}{python}{code/basic-training.2.py}
  \vspace{-0.5cm}
  \begin{itemize}
      \item An epoch refers to one pass of the training data
      \item \code{python}{output.backward()} computes $\frac{\partial L}{\partial w}$
      \item Line 8. Adjust $w$ in the opposite direction of the gradient
      \item Line 9. Reset the gradients to zero for next epoch
      \item $0.001$ is the learning rate, choosing a large learning rate will cause
        the gradients to explode
  \end{itemize}
\end{frame}

\begin{frame}{PyTorch by example: notebook}
  \begin{itemize}
    \item Let's look at \texttt{notebooks/Basic.ipynb} together
  \end{itemize}
\end{frame}

\begin{frame}{The basic steps}
  \begin{enumerate}
      \item Generate input data
      \item Generate your forward network (model)
      \item Train via back propagation
      \item Evaluate
  \end{enumerate}
\end{frame}

\begin{frame}{1. Generate your input data}
  \begin{itemize}
    \item Start with a CSV file to describe input data
  \end{itemize}
  \pygmentLines{\scriptsize}{1}{5}{text}{data/mnist.csv}
  \begin{itemize}
    \item Handwritten image data set, e.g. \texttt{0.png}
  \end{itemize}
  \begin{center}
    \ig{0.25}{figures/0.png}
  \end{center}
\end{frame}

\begin{frame}{Building an example \python{Dataset}}
  \pygment{\scriptsize}{python}{code/basic-dataset.py}
\end{frame}

\begin{frame}{Building and example \python{DataLoader}}
  \pygment{\scriptsize}{python}{code/basic-dataloader.py}
  \vspace{-0.5cm}
  \begin{itemize}
    \item What is the type of $X$ and $y$?
    \item What is the length of $X$ and $y$?
  \end{itemize}
\end{frame}

\begin{frame}{Let's implement a custom \python{DataLoader}}
  \begin{itemize}
    \item Try to implement a \python{Dataset} and \python{DataLoader} which
      compute the mean of the pixel values
    \item Result should be $31.13$
    \item Loading an image with Pillow:
  \end{itemize}
  \pygment{\scriptsize}{python}{code/pil-open.py}
\end{frame}

\begin{frame}{Example implementation}
  \begin{itemize}
    \item Let's look at \texttt{notebooks/MeanAndStandardDeviation.ipynb} together
  \end{itemize}
\end{frame}

\begin{frame}{Building the MNIST inputs}
  \begin{itemize}
    \item mean: $31.13$; standard deviation: $75.97$
    \item Apply z-score to smooth out gradients
    \item \texttt{torchvision} has a module called \texttt{transforms}
    \begin{itemize}
      \item \python{transforms.Compose} concatenates transforms together
      \item \python{transforms.ToTensor} takes a PIL Image $(H, W, C)$
        in $[0, 255]$ and converts to Tensor $(C, H, W)$
      \item \python{transforms.Normalize} takes mean and standard deviation
        $(C)$ and applies z-score to all pixels
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Building the MNIST inputs}
  \begin{itemize}
    \item Let's look at \texttt{notebooks/MNISTVanilla.ipynb} together
  \end{itemize}
\end{frame}

\begin{frame}{Building a basic dense network}
  \begin{itemize}
    \item Let's build a basic neural net using \python{torch.nn.Sequential}
  \end{itemize}
  \pygment{\scriptsize}{python}{code/basic-dense-model.py}
\end{frame}

\begin{frame}{An example dense network}
  \ig{1.0}{figures/dense-neural-net.png}
  \vspace{-0.5cm}
  \begin{itemize}
    \item How many parameters are in this model?
  \end{itemize}
\end{frame}

\begin{frame}{Optimizer and loss function}
  \begin{itemize}
    \item \namedUrl{https://arxiv.org/abs/1412.6980}{Adam Optimizer}
    \item \namedUrl{https://pytorch.org/docs/stable/nn.html\#crossentropyloss}{Cross Entropy Loss}
  \end{itemize}
  \pygment{\scriptsize}{python}{code/optimizer-loss-fn.py}
\end{frame}

\begin{frame}{Training the basic dense forward network}
  \begin{itemize}
    \item The number of ``epochs'' describes how many times the model sees the dataset
  \end{itemize}
  \pygment{\scriptsize}{python}{code/training-dense-model.py}
\end{frame}

\begin{frame}{Building a basic dense network: notebook}
  \begin{itemize}
    \item Let's look at \texttt{notebooks/BasicDense.ipynb} together
  \end{itemize}
\end{frame}

\begin{frame}{Convolutional neural net: a 2D convolution}
  \centering
  \ig{0.75}{figures/convolution.png}
  \begin{align*}
    \mathrm{kernel} &= (3, 3) \\
    \mathrm{stride} &= (1, 1) \\
    y_0 &= x_0 \times w_0 + w_1 \times x_0 + \dots \\
    y_1 &= x_1 \times w_0 + w_2 \times x_0 + \dots
  \end{align*}
  \begin{itemize}
    \item Convolutional Neural Net (CNN)
  \end{itemize}
\end{frame}

\begin{frame}{Convolutional neural net: transfer learning}
  \begin{itemize}
    \item Constructing CNNs is an art
    \item Use the years of research in the field to your advantage
    \item Instead of rolling your own, use an existing one!
    \item We'll start with the pretrained weights and adjust them to our problem
    \item But wait, my problem is really different than ImageNet?
  \end{itemize}
\end{frame}

\begin{frame}{CNN via transfer learning}
  \begin{itemize}
    \item Most of the pretrained models require a 224x224 image
    \item \python{pretrained=False} will yield randomly initialized weights
  \end{itemize}
  \pygment{\scriptsize}{python}{code/transfer-model.py}
\end{frame}

\begin{frame}{CNN via transfer learning: notebook}
  \begin{itemize}
    \item Let's look at \texttt{notebooks/BasicTransfer.ipynb} together
  \end{itemize}
\end{frame}

\begin{frame}{Practical considerations}
  \begin{itemize}
    \item Metrics should be on data held out from the training data
    \item Imbalanced datasets are extremely common, trivial upsampling:
    \begin{itemize}
      \item Generate max (or mean) count $mc$ per label
      \item Get the number of rows for that label $nl$
      \item Duplicate labeled rows up to $mc\ //\ nl$
      \item Randomly sample rows up to $mc\ \%\ l$
      \item Combine duplicates and random samples into new dataset
    \end{itemize}
    \item Adding noise to images can help generalize models
      \namedUrl{https://pytorch.org/docs/stable/torchvision/transforms.html}{Torchvision
      transforms} has PIL \python{Image} transformations
  \end{itemize}
\end{frame}

\begin{frame}{What next?}
  \unnamedUrl{https://forms.gle/YWN8uXhiZLkbvXBM6}
\end{frame}

\end{document}
